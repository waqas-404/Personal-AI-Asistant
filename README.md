<div align="center">

# ü§ñ ORA
### Orchestration Based Retrieval Agent

*A real-time, voice-driven AI assistant for intelligent automation, web intelligence, and multimodal generation*

[![Python](https://img.shields.io/badge/Python-3.10-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![Groq](https://img.shields.io/badge/Groq-LLM-F55036?style=for-the-badge&logo=groq&logoColor=white)](https://groq.com)
[![Edge TTS](https://img.shields.io/badge/Edge_TTS-Voice-0078D4?style=for-the-badge&logo=microsoft&logoColor=white)](https://github.com/rany2/edge-tts)


</div>

---

## Overview

Modern AI assistants stop at conversation. **ORA goes further.**

ORA is a fully voice-driven, desktop AI assistant engineered for real-time reasoning, system automation, web intelligence retrieval, and multimodal generation ‚Äî all through natural conversation. Built with a production-style modular architecture, it demonstrates applied AI engineering, orchestration logic, and real-world automation in a single cohesive system.

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        USER (Voice Input)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SpeechRecognition                         ‚îÇ
‚îÇ            Google Speech API  ¬∑  PyAudio  ¬∑  mtranslate      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Decision Model  (Groq ¬∑ llama-3.1-8b)           ‚îÇ
‚îÇ         Query Classification  ¬∑  Tool Routing  ¬∑  Context    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ          ‚îÇ          ‚îÇ          ‚îÇ           ‚îÇ
       ‚ñº          ‚ñº          ‚ñº          ‚ñº           ‚ñº
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ General ‚îÇ ‚îÇAutomation‚îÇ ‚îÇ  Web   ‚îÇ ‚îÇ Image  ‚îÇ ‚îÇRealtime  ‚îÇ
  ‚îÇ Chatbot ‚îÇ ‚îÇ& System  ‚îÇ ‚îÇSearch  ‚îÇ ‚îÇ  Gen   ‚îÇ ‚îÇ Search   ‚îÇ
  ‚îÇ (Groq)  ‚îÇ ‚îÇ(AppOpen) ‚îÇ ‚îÇ(DDGS)  ‚îÇ ‚îÇ (HF)   ‚îÇ ‚îÇ(Scraper) ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Response Formatting                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Edge-TTS  ¬∑  pygame  ¬∑  PyQt5 GUI              ‚îÇ
‚îÇ                     (Voice + Visual Output)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Core Capabilities

| Module | Capability | Technology |
|--------|-----------|------------|
| üé§ **Voice Input** | Continuous listening, multilingual support, ambient noise calibration | `SpeechRecognition`, `PyAudio`, `mtranslate` |
| üß† **Decision Engine** | Query classification, tool routing, context-aware orchestration | `Groq` ¬∑ `llama-3.1-8b-instant` |
| üí¨ **General Chat** | Conversational AI with persistent session memory | `Groq`, `Cohere` |
| üåê **Web Intelligence** | Live search, dynamic content extraction, browser automation | `DDGS`, `BeautifulSoup`, `Selenium` |
| üñ•Ô∏è **System Automation** | Open/close apps, YouTube, Google search, volume, reminders | `AppOpener`, `pywhatkit`, `keyboard` |
| üñºÔ∏è **Image Generation** | Prompt-based image generation and processing | `Hugging Face API`, `Pillow` |
| üîä **Voice Output** | Natural, low-latency speech synthesis | `edge-tts`, `pygame` |
| üñºÔ∏è **GUI** | Real-time chat display, status indicators | `PyQt5` |

---

## Project Structure

```
ORA/
‚îÇ
‚îú‚îÄ‚îÄ Frontend/
‚îÇ   ‚îî‚îÄ‚îÄ GUI.py                  # PyQt5 interface & status rendering
‚îÇ
‚îú‚îÄ‚îÄ Backend/
‚îÇ   ‚îú‚îÄ‚îÄ Model.py                # Groq decision-making & query classification
‚îÇ   ‚îú‚îÄ‚îÄ Chatbot.py              # General conversational AI
‚îÇ   ‚îú‚îÄ‚îÄ RealTimeSearchEngine.py # Live web search & content extraction
‚îÇ   ‚îú‚îÄ‚îÄ Automation.py           # System automation & app control
‚îÇ   ‚îú‚îÄ‚îÄ SpeechToText.py         # Voice capture & recognition pipeline
‚îÇ   ‚îú‚îÄ‚îÄ TextToSpeech.py         # Edge-TTS synthesis & playback
‚îÇ   ‚îî‚îÄ‚îÄ ImageGeneration.py      # Hugging Face image generation
‚îÇ
‚îú‚îÄ‚îÄ Data/
‚îÇ   ‚îú‚îÄ‚îÄ ChatLog.json            # Persistent conversation history
‚îÇ   ‚îî‚îÄ‚îÄ speech.mp3              # TTS audio buffer
‚îÇ
‚îú‚îÄ‚îÄ Frontend/Files/             # Runtime status & IPC data files
‚îú‚îÄ‚îÄ Main.py                     # Orchestration entry point
‚îú‚îÄ‚îÄ .env                        # Secrets & configuration
‚îî‚îÄ‚îÄ requirements.txt
```

---

## Setup & Installation

### Prerequisites
- Python 3.10 (recommended)
- A microphone
- API keys for Groq and Hugging Face

### 1. Clone the Repository
```bash
git clone https://github.com/waqas-404/Personal-AI-Asistant
```

### 2. Create Virtual Environment
```bash
py -3.10 -m venv .venv
```
```bash
# Windows
.venv\Scripts\activate

# macOS / Linux
source .venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r Requirements.txt
```

### 4. Configure Environment Variables

Create a `.env` file in the project root:

```env
CohereAPIKey = "Your cohere API key"
Username = Waqas Kareem #You can set any user name 
Assistantname = ORA
GroqAPIKey = "Your Groq API key"
InputLanguage = en
AssistantVoice = en-CA-LiamNeural
HuggingFaceAPIKey = "Enter you hugging face API key"
```

> Get your free Groq API key at [console.groq.com](https://console.groq.com)
> Get your Hugging Face key at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

### 5. Run ORA
```bash
python Main.py
```

Speak naturally ‚Äî ORA handles the rest.

---

## Tech Stack

### AI & Inference
![Groq](https://img.shields.io/badge/Groq-F55036?style=flat-square&logo=groq&logoColor=white)
![HuggingFace](https://img.shields.io/badge/Hugging_Face-FFD21E?style=flat-square&logo=huggingface&logoColor=black)
![Cohere](https://img.shields.io/badge/Cohere-39594C?style=flat-square&logoColor=white)

### Voice Stack
![SpeechRecognition](https://img.shields.io/badge/SpeechRecognition-4285F4?style=flat-square&logo=google&logoColor=white)
![EdgeTTS](https://img.shields.io/badge/Edge_TTS-0078D4?style=flat-square&logo=microsoft&logoColor=white)
![PyAudio](https://img.shields.io/badge/PyAudio-3776AB?style=flat-square&logo=python&logoColor=white)

### Automation & Web
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=flat-square&logo=selenium&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-3776AB?style=flat-square&logo=python&logoColor=white)
![AppOpener](https://img.shields.io/badge/AppOpener-gray?style=flat-square)

### Interface
![PyQt5](https://img.shields.io/badge/PyQt5-41CD52?style=flat-square&logo=qt&logoColor=white)
![Pygame](https://img.shields.io/badge/Pygame-376F9F?style=flat-square&logo=python&logoColor=white)

---

## Engineering Highlights

- **Sub-second decision routing** via `llama-3.1-8b-instant` on Groq ‚Äî classification latency under 0.5s
- **Eliminated browser-based STT** ‚Äî replaced Selenium/Chrome Web Speech API with direct Google Speech API calls, reducing STT latency from ~34s to ~2s
- **Persistent pygame mixer** ‚Äî initialized once at startup rather than per TTS call, eliminating ~3s overhead per response
- **Single persistent asyncio event loop** for TTS generation ‚Äî no per-call loop creation/destruction overhead
- **Modular tool-routing architecture** ‚Äî clean separation of concerns across all AI modules
- **Environment-based secure API management** ‚Äî no hardcoded credentials

---

## Roadmap

- [ ] Wake-word activation
- [ ] Persistent long-term memory
- [ ] Cross-platform packaging (Windows installer / macOS app)
- [ ] Multi-agent orchestration layer
- [ ] Performance profiling dashboard
- [ ] Cloud deployment support

---

## Author

**Waqas Kareem**
*AI/ML Engineer ¬∑ Automation Developer ¬∑ Software Engineer*

[![GitHub](https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/waqas-404)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=flat-square&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/waqas-kareem-mlengineer/)

---

<div align="center">
<sub>Built with ‚ù§Ô∏è ‚Äî ORA is open to contributions, feedback, and collaboration.</sub>
</div>
